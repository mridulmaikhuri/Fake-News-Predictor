{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d275884",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b1bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb5e959",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ddb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/Fake.csv')\n",
    "df2 = pd.read_csv('../data/True.csv')\n",
    "\n",
    "df1['label'] = 0\n",
    "df2['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eaa360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3994472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df['content'] = df['title'] + ' ' + df['text']\n",
    "df = df[['content', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4846a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bed946",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['content'], df['label'], test_size=0.2, random_state=42\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2464a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa68b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac56b39",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66194457",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4072748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes characters that are not useful for text analysis\n",
    "def remove_unwanted_chars(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # remove URLs\n",
    "    text = re.sub(r'<.*?>', '', text) # remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # remove special characters and numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # remove extra spaces\n",
    "    \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Removes stopwords and lemmatizes the text\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_stop\n",
    "    ]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = remove_unwanted_chars(text)\n",
    "    text = lemmatize_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cabb460",
   "metadata": {},
   "source": [
    "## Defining the complete ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b881a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the complete ML pipeline steps for this baseline model\n",
    "pipeline = Pipeline([\n",
    "    (\n",
    "        'tfidf', \n",
    "        TfidfVectorizer(\n",
    "            preprocessor=preprocess_text,\n",
    "            max_df=0.9,\n",
    "            min_df=5,\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "    ),\n",
    "    (\n",
    "        'clf', \n",
    "        LogisticRegression(\n",
    "            solver='liblinear', \n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66f6f9",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faffbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3013ccf",
   "metadata": {},
   "source": [
    "## Predicting results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc77e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9921b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.concatenate([y_test.values.reshape(-1,1), y_pred.reshape(-1,1)], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd0525",
   "metadata": {},
   "source": [
    "## Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a770abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred, target_names=['Fake', 'Real'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5810bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3fa567",
   "metadata": {},
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pipeline.named_steps['tfidf'].get_feature_names_out()\n",
    "coefficients = pipeline.named_steps['clf'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    'word': feature_names,\n",
    "    'weight': coefficients\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368592b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fake = coef_df.sort_values(by='weight', ascending=True).head(20)\n",
    "top_real = coef_df.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.barh(top_fake['word'], top_fake['weight'])\n",
    "plt.title(\"Top words indicating FAKE news\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.barh(top_real['word'], top_real['weight'])\n",
    "plt.title(\"Top words indicating REAL news\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04695f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = X_test.iloc[0]\n",
    "\n",
    "vectorizer = pipeline.named_steps['tfidf']\n",
    "model = pipeline.named_steps['clf']\n",
    "\n",
    "X_vec = vectorizer.transform([text])\n",
    "feature_index = X_vec.nonzero()[1]\n",
    "\n",
    "contributions = pd.DataFrame({\n",
    "    'word': feature_names[feature_index],\n",
    "    'contribution': coefficients[feature_index] * X_vec.data\n",
    "}).sort_values(by='contribution', ascending=True)\n",
    "\n",
    "pred = pipeline.predict([text])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The predicted label for the given text is:\", \"REAL\" if pred == 1 else \"FAKE\", \"\\n\")\n",
    "print(\"The real label for the given text is:\", \"REAL\" if y_test.iloc[0] == 1 else \"FAKE\", \"\\n\")\n",
    "\n",
    "print(\"Top words pushing prediction towards FAKE:\\n\")\n",
    "print(contributions.head(10), \"\\n\")\n",
    "\n",
    "print(\"Top words pushing prediction towards REAL:\\n\")\n",
    "print(contributions.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b1d0bc",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5882a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "class_names = ['FAKE', 'REAL']\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    text,\n",
    "    pipeline.predict_proba, \n",
    "    num_features=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(exp.as_html()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
